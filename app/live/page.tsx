'use client';
import React, { useState, useEffect, useRef, useMemo } from 'react';
import { UserOutlined, RobotOutlined } from '@ant-design/icons';
import { PauseCircleOutlined, PoweroffOutlined, AudioOutlined, StopOutlined, DownloadOutlined } from '@ant-design/icons';
import MediaButtons from '@/components/media-buttons';
import { useLiveAPIContext } from '@/vendor/contexts/LiveAPIContext';
import {
	RealtimeInputMessage,
	ClientContentMessage,
	ServerContentMessage,
} from '@/vendor/multimodal-live-types';
import { base64sToArrayBuffer, pcmBufferToBlob } from '@/vendor/lib/utils';
import { useConversationRecorder, formatDuration, downloadRecording, cleanupRecordingUrls } from '@/vendor/hooks/use-conversation-recorder';

import {
	Button,
	Layout,
	theme,
	Collapse,
	Input,
	Flex,
	Select,
	Tag,
	Checkbox,
	Modal,
	// App, // no longer using App.useApp modal
} from 'antd';
import { Sender, Bubble } from '@ant-design/x';
import { useLocalStorageState } from 'ahooks';
import FieldItem from '@/components/field-item';
import ChatExport from '@/components/chat-export';
import GeminiIcon from '@/app/icon/google-gemini-icon.svg';
import Image from 'next/image';
import { GPTVis } from '@antv/gpt-vis';
import { Part } from '@google/generative-ai';

const { Header, Content } = Layout;

interface ToolsState {
	grounding: boolean;
	speechToText: boolean;
}

const fooAvatar: React.CSSProperties = {
	color: '#f56a00',
	backgroundColor: '#fde3cf',
};

const barAvatar: React.CSSProperties = {
	color: '#fff',
	backgroundColor: '#1677ff',
};

type MessageType =
	| RealtimeInputMessage
	| ClientContentMessage
	| ServerContentMessage
	| null;

const isClientMessage = (
	message: MessageType
): message is ClientContentMessage => {
	return message !== null && 'clientContent' in message;
};

const isServerMessage = (
	message: MessageType
): message is ServerContentMessage => {
	return message !== null && 'serverContent' in message;
};

const hasModelTurn = (
	content: ServerContentMessage['serverContent']
): content is { modelTurn: { parts: Part[] } } => {
	return 'modelTurn' in content && content.modelTurn !== null;
};

const MessageItem: React.FC<{ message: MessageType; outputMode: string }> = ({
	message,
	outputMode,
}) => {
	const textComponent = useMemo(() => {
		if (isClientMessage(message)) {
			const content = message.clientContent.turns?.[0]?.parts
				.map((p) => p.text)
				.join('');
			return content ? (
				<Bubble
					key={message.id}
					placement='end'
					content={<GPTVis>{content}</GPTVis>}
					typing={{ step: 2, interval: 50 }}
					avatar={{
						icon: <UserOutlined />,
						style: fooAvatar,
					}}
				/>
			) : null;
		}

		if (isServerMessage(message) && hasModelTurn(message.serverContent)) {
			const content = message.serverContent.modelTurn.parts
				.map((p) => p?.text ?? '')
				.join('');
			return content ? (
				<Bubble
					key={message.id}
					placement='start'
					content={<GPTVis>{content}</GPTVis>}
					typing={{ step: 10, interval: 50 }}
					avatar={{
						icon: <RobotOutlined />,
						style: barAvatar,
					}}
				/>
			) : null;
		}
		return null;
	}, [message]);

	const audioComponent = useMemo(() => {
		// åœ¨audio_textæ¨¡å¼ä¸‹ï¼Œä¸æ¸²æŸ“éŸ³é¢‘ç»„ä»¶
		if (outputMode === 'audio_text') {
			return null;
		}
		if (isServerMessage(message) && hasModelTurn(message.serverContent)) {
			const audioParts = message.serverContent.modelTurn?.parts.filter(
				(p) => p.inlineData
			);
			if (audioParts.length) {
				const base64s = audioParts
					.map((p) => p.inlineData?.data)
					.filter((data): data is string => data !== undefined);
				const buffer = base64sToArrayBuffer(base64s);
				const blob = pcmBufferToBlob(buffer, 24000);
				const audioUrl = URL.createObjectURL(blob);
				return (
					<Bubble
						key={`audio-${message.id}`}
						placement='start'
						content={
							<div>
								<audio
									style={{
										height: 30,
									}}
									controls
									src={audioUrl}
								/>
							</div>
						}
						avatar={{
							icon: <RobotOutlined />,
							style: barAvatar,
						}}
						styles={{
							content: {
								padding: 8,
							},
						}}
					/>
				);
			}
		}
		return null;
	}, [message, outputMode]);

	return (
		<>
			{textComponent}
			{audioComponent}
		</>
	);
};

const LivePage: React.FC = () => {
	// const { modal } = App.useApp();
	const {
		token: {
			colorBgLayout,
			colorFillAlter,
			borderRadiusLG,
			colorBgContainer,
		},
	} = theme.useToken();
	const videoRef = useRef<HTMLVideoElement>(null);
	// either the screen capture, the video or null, if null we hide it
	const [videoStream, setVideoStream] = useState<MediaStream | null>(null);

	const {
		client,
		config,
		setConfig,
		connected,
		connect,
		disconnect,
		currentBotMessage,
		currentUserMessage,
		currentTranscriptMessage,
		setOutputMode,
		transcribedText,
		setSpeechToTextEnabled,
		audioRecorder,
		audioStreamer,
	} = useLiveAPIContext();

	// å½•åˆ¶åŠŸèƒ½
	const {
		isRecording,
		duration,
		startRecording,
		stopRecording,
		error: recordingError,
		recordingUrls,
	} = useConversationRecorder(audioRecorder, audioStreamer);

	// ç›‘å¬è¿æ¥å¼‚å¸¸æ–­å¼€ï¼Œå¼¹çª—æç¤º
	useEffect(() => {
		const onClose = (ev: CloseEvent) => {
			// 1000 è¡¨ç¤ºæ­£å¸¸å…³é—­ï¼Œå…¶ä»–ä¸ºå¼‚å¸¸/é”™è¯¯
			if (ev.code !== 1000) {
				const reason = ev?.reason || 'æœªçŸ¥åŸå› ';
				Modal.error({
					title: 'è¿æ¥å·²æ–­å¼€',
					content: `WebSocket å·²æ–­å¼€ï¼ˆä»£ç  ${ev.code}ï¼‰ã€‚${reason ? `åŸå› ï¼š${reason}` : ''}ã€‚\nè¯·æ£€æŸ¥ç½‘ç»œã€API Keyï¼ˆNEXT_PUBLIC_GEMINI_API_KEYï¼‰æˆ–æ¨¡å‹/æƒé™é…ç½®åé‡è¯•ã€‚`,
					okText: 'å¥½çš„',
				});
			}
		};
		client.on('close', onClose);
		return () => {
			client.off('close', onClose);
		};
	}, [client]);

	const [textInput, setTextInput] = useState('');

	const [prompt, setPrompt] = useLocalStorageState('prompt', {
		defaultValue: '',
	});
	const [model, setModel] = useLocalStorageState('model', {
		defaultValue: 'gemini-live-2.5-flash-preview',
	});
	const [outPut, setOutPut] = useLocalStorageState('output', {
		defaultValue: 'audio',
	});

	useEffect(() => {
		setOutputMode(outPut);
	}, [outPut, setOutputMode]);

	const [voice, setVoice] = useLocalStorageState('voice', {
		defaultValue: 'Puck',
	});

	const [tools, setTools] = useLocalStorageState<ToolsState>('tools', {
		defaultValue: {
			grounding: false,
			speechToText: true,
		},
	});

	// VoskæœåŠ¡çŠ¶æ€ç®¡ç†
	const [voskServiceStatus, setVoskServiceStatus] = useState<'running' | 'stopped' | 'checking'>('checking');
	const [voskServiceProcess, setVoskServiceProcess] = useState<string | null>(null);

	// æ£€æŸ¥VoskæœåŠ¡çŠ¶æ€
	const checkVoskServiceStatus = async () => {
		try {
			setVoskServiceStatus('checking');
			const response = await fetch('http://localhost:5001/health');
			if (response.ok) {
				setVoskServiceStatus('running');
			} else {
				setVoskServiceStatus('stopped');
			}
		} catch (error) {
			setVoskServiceStatus('stopped');
		}
	};

	// å¯åŠ¨VoskæœåŠ¡
	const startVoskService = async () => {
		try {
			setVoskServiceStatus('checking');
			
			// åˆ›å»ºä¸€ä¸ªæ–°çš„ç»ˆç«¯æ¥è¿è¡ŒPythonæœåŠ¡
			const response = await fetch('/api/vosk/start', {
				method: 'POST',
				headers: {
					'Content-Type': 'application/json',
				},
			});
			
			if (response.ok) {
				const data = await response.json();
				setVoskServiceProcess(data.processId);
				// ç­‰å¾…ä¸€ä¸‹å†æ£€æŸ¥çŠ¶æ€
				setTimeout(() => {
					checkVoskServiceStatus();
				}, 2000);
				Modal.success({
					title: 'å¯åŠ¨æˆåŠŸ',
					content: 'VoskæœåŠ¡æ­£åœ¨å¯åŠ¨ä¸­...',
					okText: 'å¥½çš„',
				});
			} else {
				throw new Error('å¯åŠ¨å¤±è´¥');
			}
		} catch (error) {
			console.error('å¯åŠ¨VoskæœåŠ¡å¤±è´¥:', error);
			setVoskServiceStatus('stopped');
			Modal.error({
				title: 'å¯åŠ¨å¤±è´¥',
				content: 'è¯·ç¡®ä¿Pythonç¯å¢ƒå·²å®‰è£…å¹¶ä¸”vosk_service.pyæ–‡ä»¶å­˜åœ¨',
				okText: 'å¥½çš„',
			});
		}
	};

	// åœæ­¢VoskæœåŠ¡
	const stopVoskService = async () => {
		try {
			setVoskServiceStatus('checking');
			
			const response = await fetch('/api/vosk/stop', {
				method: 'POST',
				headers: {
					'Content-Type': 'application/json',
				},
				body: JSON.stringify({ processId: voskServiceProcess }),
			});
			
			if (response.ok) {
				setVoskServiceProcess(null);
				setVoskServiceStatus('stopped');
				Modal.success({
					title: 'åœæ­¢æˆåŠŸ',
					content: 'VoskæœåŠ¡å·²åœæ­¢',
					okText: 'å¥½çš„',
				});
			} else {
				throw new Error('åœæ­¢å¤±è´¥');
			}
		} catch (error) {
			console.error('åœæ­¢VoskæœåŠ¡å¤±è´¥:', error);
			Modal.error({
				title: 'åœæ­¢å¤±è´¥',
				content: 'æ— æ³•åœæ­¢VoskæœåŠ¡ï¼Œè¯·æ‰‹åŠ¨ç»ˆæ­¢è¿›ç¨‹',
				okText: 'å¥½çš„',
			});
			// é‡æ–°æ£€æŸ¥çŠ¶æ€
			checkVoskServiceStatus();
		}
	};

	// å®šæœŸæ£€æŸ¥VoskæœåŠ¡çŠ¶æ€
	useEffect(() => {
		checkVoskServiceStatus();
		const interval = setInterval(checkVoskServiceStatus, 5000); // æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
		return () => clearInterval(interval);
	}, []);

	// åŒæ­¥è¯­éŸ³è½¬æ–‡å­—è®¾ç½®
	useEffect(() => {
		if (tools?.speechToText !== undefined) {
			setSpeechToTextEnabled(tools.speechToText);
		}
	}, [tools?.speechToText, setSpeechToTextEnabled]);

	const [toolsPaneActive, setToolsPaneActive] = useLocalStorageState<
		string[]
	>('tools-pane-active', {
		defaultValue: [],
	});

	const [messages, setMessages] = useState<MessageType[]>([]);

	const handleSubmit = () => {
		if (!connected) {
			Modal.error({
				title: 'æœªè¿æ¥åˆ°æœåŠ¡',
				content: 'è¯·å…ˆç‚¹å‡»å¼€å§‹è¿æ¥ï¼Œç„¶åå†å‘é€æ–‡æœ¬ã€‚',
				okText: 'å¥½çš„',
			});
			return;
		}
		client.send([{ text: textInput }]);
		setTextInput('');
	};

	useEffect(() => {
		console.log('currentBotMessage', currentBotMessage);
		if (currentBotMessage) {
			setMessages((messages) => {
				if (
					messages.filter((m) => m?.id === currentBotMessage?.id)
						.length > 0
				) {
					return messages.map((m) =>
						m?.id === currentBotMessage?.id ? currentBotMessage : m
					);
				} else {
					return [...messages, currentBotMessage];
				}
			});
		}
	}, [currentBotMessage]);

	// åœ¨ Audio+Text ä¸‹ï¼Œå°†æœ€ç»ˆè½¬å†™ç»“æœä½œä¸ºä¸€æ¡å¯¹è¯æ¶ˆæ¯åŠ å…¥å†å²
	useEffect(() => {
		console.log('currentTranscriptMessage', currentTranscriptMessage);
		if (currentTranscriptMessage) {
			setMessages((messages) => {
				if (
					messages.filter((m) => m?.id === currentTranscriptMessage?.id)
						.length > 0
				) {
					return messages.map((m) =>
						m?.id === currentTranscriptMessage?.id
							? currentTranscriptMessage
							: m
					);
				} else {
					return [...messages, currentTranscriptMessage];
				}
			});
		}
	}, [currentTranscriptMessage]);

	useEffect(() => {
		console.log('currentUserMessage', currentUserMessage);
		if (currentUserMessage) {
			setMessages((messages) => {
				if (
					messages.filter((m) => m?.id === currentUserMessage?.id)
						.length > 0
				) {
					return messages.map((m) =>
						m?.id === currentUserMessage?.id
							? currentUserMessage
							: m
					);
				} else {
					return [...messages, currentUserMessage];
				}
			});
		}
	}, [currentUserMessage]);

	console.log('messages', messages);

	useEffect(() => {
		const speechConfig = {
			voiceConfig: {
				prebuiltVoiceConfig: {
					voiceName: voice,
				},
			},
		};

		// æ ¹æ®è¾“å‡ºæ¨¡å¼è®¾ç½®responseModalities
		let responseModalities: 'text' | 'audio' | 'image';
		if (outPut === 'audio_text') {
			// audio_text æ¨¡å¼ï¼šéœ€è¦éŸ³é¢‘è¾“å‡ºä¾›Voskè½¬å½•ï¼Œæ‰€ä»¥è®¾ç½®ä¸ºaudio
			responseModalities = 'audio';
		} else if (outPut === 'audio') {
			responseModalities = 'audio';
		} else {
			responseModalities = 'text';
		}

		const generationConfig = {
			...config?.generationConfig,
			speechConfig,
			responseModalities,
		} as typeof config.generationConfig;
		const systemInstruction = prompt
			? { parts: [{ text: prompt }] }
			: undefined;
		setConfig({ ...config, model: `models/${model}`, generationConfig, systemInstruction });
		// eslint-disable-next-line react-hooks/exhaustive-deps
	}, [connected, prompt, model, outPut, voice]);

	const panelStyle: React.CSSProperties = {
		background: colorFillAlter,
		borderRadius: borderRadiusLG,
		border: 'none',
	};

	const handleDisconnect = async () => {
		// å¦‚æœæ­£åœ¨å½•åˆ¶ï¼Œå…ˆåœæ­¢å½•åˆ¶
		if (isRecording) {
			try {
				await stopRecording();
			} catch (err) {
				console.error('åœæ­¢å½•åˆ¶å¤±è´¥:', err);
			}
		}
		setVideoStream(null);
		disconnect();
	};

	const handleConnect = async () => {
		try {
			await connect();
		} catch (err: any) {
			Modal.error({
				title: 'è¿æ¥å¤±è´¥',
				content:
					(err?.message || 'æ— æ³•è¿æ¥åˆ° Gemini Live æœåŠ¡') +
					'ã€‚è¯·æ£€æŸ¥ç½‘ç»œã€API Keyï¼ˆNEXT_PUBLIC_GEMINI_API_KEYï¼‰æ˜¯å¦æ­£ç¡®ï¼Œå¹¶ç¡®è®¤æ¨¡å‹ä¸æƒé™é…ç½®æ— è¯¯ã€‚',
				okText: 'å¥½çš„',
			});
		}
	};

	// å½•åˆ¶æ§åˆ¶å‡½æ•°
	const handleStartRecording = async () => {
		if (!connected) {
			Modal.warning({
				title: 'æ— æ³•å¼€å§‹å½•åˆ¶',
				content: 'è¯·å…ˆè¿æ¥åˆ° Gemini Live æœåŠ¡',
				okText: 'å¥½çš„',
			});
			return;
		}
		try {
			await startRecording();
		} catch (err: any) {
			Modal.error({
				title: 'å¼€å§‹å½•åˆ¶å¤±è´¥',
				content: err?.message || 'æ— æ³•å¼€å§‹å½•åˆ¶',
				okText: 'å¥½çš„',
			});
		}
	};

	const handleStopRecording = async () => {
		try {
			const urls = await stopRecording();
			if (urls) {
				Modal.success({
					title: 'å½•åˆ¶å®Œæˆ',
					content: 'å¯¹è¯å½•åˆ¶å·²å®Œæˆï¼Œæ‚¨å¯ä»¥ä¸‹è½½å½•åˆ¶æ–‡ä»¶ã€‚',
					okText: 'å¥½çš„',
				});
			}
		} catch (err: any) {
			Modal.error({
				title: 'åœæ­¢å½•åˆ¶å¤±è´¥',
				content: err?.message || 'æ— æ³•åœæ­¢å½•åˆ¶',
				okText: 'å¥½çš„',
			});
		}
	};

	// ä¸‹è½½å½•åˆ¶æ–‡ä»¶
	const handleDownloadRecording = (type: 'mic' | 'api' | 'mixed') => {
		if (!recordingUrls) return;
		
		const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
		const urls = {
			mic: recordingUrls.micUrl,
			api: recordingUrls.apiUrl,
			mixed: recordingUrls.mixedUrl,
		};
		const filenames = {
			mic: `conversation-mic-${timestamp}.wav`,
			api: `conversation-api-${timestamp}.wav`,
			mixed: `conversation-mixed-${timestamp}.wav`,
		};
		
		downloadRecording(urls[type], filenames[type]);
	};

	// æ¸…ç†å½•åˆ¶æ–‡ä»¶URLs
	useEffect(() => {
		return () => {
			if (recordingUrls) {
				cleanupRecordingUrls(recordingUrls);
			}
		};
	}, [recordingUrls]);

	return (
		<Layout
			style={{
				height: '100vh',
			}}
		>
			<Header
				style={{
					padding: '0 12px 0 24px',
					background: colorBgLayout,
					fontSize: 22,
					fontWeight: 500,
				}}
			>
				Stream Realtime
			</Header>
			<Flex
				style={{
					height: 'calc(100vh - 64px)',
					overflow: 'hidden',
				}}
			>
				<Content
					style={{
						background: colorBgContainer,
						borderRadius: 20,
						flex: 1,
						overflow: 'hidden',
					}}
				>
					<Flex style={{ height: '100%' }}>
						<Flex
							vertical
							flex={1}
							style={{
								borderRadius: 20,
								background: '#fff',
								position: 'relative',
								overflow: 'hidden',
							}}
						>

							{/* æ¶ˆæ¯å·¥å…·æ  */}
							<div
								style={{
									padding: '8px 24px',
									borderBottom: '1px solid #f0f0f0',
									background: '#fafafa',
								}}
							>
								<Flex justify='space-between' align='center'>
									<span style={{ fontSize: '14px', color: '#666' }}>
										å¯¹è¯å†å² ({messages.filter(m => m !== null).length} æ¡æ¶ˆæ¯)
									</span>
									<ChatExport messages={messages} disabled={!connected} />
								</Flex>
							</div>
							<div
								className='messages'
								style={{
									flex: 1,
									padding: 24,
									overflowY: 'auto',
									boxSizing: 'border-box',
									borderRadius: 20,
									height: 0,
								}}
							>
								<Flex gap='middle' vertical>
								{messages.map((m) => (
									<MessageItem key={m?.id} message={m} outputMode={outPut} />
								))}
								{/* åœ¨Audio+Textæ¨¡å¼ä¸‹æ˜¾ç¤ºå®æ—¶è½¬å†™æ–‡å­— */}
								{outPut === 'audio_text' && transcribedText && (
									<div
										style={{
											padding: '12px 16px',
											border: '1px dashed #d9d9d9',
											borderRadius: '8px',
											backgroundColor: '#f9f9f9',
											marginTop: '8px',
										}}
									>
										<div
											style={{
												fontSize: '12px',
												color: '#666',
												marginBottom: '4px',
											}}
										>
											ğŸ¤ å®æ—¶è¯­éŸ³è½¬å†™
										</div>
										<div
											style={{
												fontSize: '14px',
												color: '#333',
												lineHeight: '1.5',
											}}
										>
											{transcribedText}
										</div>
									</div>
								)}
							</Flex>
							</div>
							<Flex justify='center' gap='middle' vertical>
								<Button
									color='primary'
									variant={connected ? 'outlined' : 'solid'}
									onClick={connected ? handleDisconnect : handleConnect}
									icon={
										connected ? (
											<PauseCircleOutlined />
										) : (
											<PoweroffOutlined />
										)
									}
								>
									{connected
										? 'Disconnect'
										: 'Click me to start !'}
								</Button>
								
								{/* å½•åˆ¶æ§åˆ¶åŒºåŸŸ */}
								{connected && (
									<Flex justify='center' gap='small' align='center' wrap>
										<Button
											type={isRecording ? 'primary' : 'default'}
											danger={isRecording}
											onClick={isRecording ? handleStopRecording : handleStartRecording}
											icon={isRecording ? <StopOutlined /> : <AudioOutlined />}
											size='small'
										>
											{isRecording ? 'åœæ­¢å½•åˆ¶' : 'å¼€å§‹å½•åˆ¶'}
										</Button>
										
										{isRecording && (
											<Tag color='red'>
												å½•åˆ¶ä¸­ {formatDuration(duration)}
											</Tag>
										)}
										
										{recordingUrls && (
											<Flex gap='small'>
												<Button
													size='small'
													icon={<DownloadOutlined />}
													onClick={() => handleDownloadRecording('mixed')}
													title='ä¸‹è½½æ··åˆéŸ³é¢‘'
												>
													æ··åˆ
												</Button>
												<Button
													size='small'
													icon={<DownloadOutlined />}
													onClick={() => handleDownloadRecording('mic')}
													title='ä¸‹è½½éº¦å…‹é£éŸ³é¢‘'
												>
													éº¦å…‹é£
												</Button>
												<Button
													size='small'
													icon={<DownloadOutlined />}
													onClick={() => handleDownloadRecording('api')}
													title='ä¸‹è½½APIéŸ³é¢‘'
												>
													API
												</Button>
											</Flex>
										)}
										
										{recordingError && (
											<Tag color='red' style={{ fontSize: '12px' }}>
												é”™è¯¯: {recordingError}
											</Tag>
										)}
									</Flex>
								)}
							</Flex>
							<div
								className='px-5 py-2'
								style={{
									pointerEvents: !connected ? 'none' : 'auto',
								}}
							>
								<Sender
									onChange={setTextInput}
									onSubmit={handleSubmit}
									value={textInput}
									disabled={!connected}
									prefix={
										<MediaButtons
											videoRef={videoRef}
											supportsVideo
											onVideoStreamChange={setVideoStream}
										/>
									}
								/>
								{videoStream ? (
									<video
										style={{
											position: 'absolute',
											top: 70,
											right: 20,
											maxWidth: 300,
											borderRadius: 10,
											border: '1px solid #333',
											display: !videoStream
												? 'none'
												: 'auto',
										}}
										ref={videoRef}
										autoPlay
										playsInline
									/>
								) : null}
							</div>
						</Flex>
					</Flex>
				</Content>
				<Flex
					vertical
					gap={32}
					style={{
						width: 250,
						padding: '10px',
						overflowY: 'auto',
						background: colorBgLayout,
					}}
				>
					<div
						style={{
							fontSize: 16,
							fontWeight: 500,
						}}
					>
						Run settings
					</div>
						<Collapse
							bordered={false}
							style={{ background: colorBgContainer }}
							items={[
								{
									key: 'prompts',
									label: 'System Instructions',
									children: (
										<Input
											onChange={(e) =>
												setPrompt(
													e.target.value
												)
											}
											value={prompt}
											placeholder='Optional tone and style instructions for the model'
										/>
									),
									style: panelStyle,
								},
							]}
						/>
						<FieldItem
							label='Model'
							icon={<Image src={GeminiIcon} alt={'Model'} />}
						>
						<Select
							popupMatchSelectWidth={false}
							onChange={setModel}
							value={model}
							options={[
								{
									value: 'gemini-live-2.5-flash-preview',
									label: (
										<span>
											<span
												style={{
													marginRight: 8,
												}}
											>
												Gemini 2.5 Flash Live Preview
											</span>
											<Tag
												style={{
													marginRight: 0,
												}}
												color='#87d068'
											>
												New
											</Tag>
										</span>
									),
								},
							]}
						/>
					</FieldItem>
					<FieldItem label='Output format'>
						<Select
							onChange={setOutPut}
							value={outPut}
							options={[
								{
									value: 'audio',
									label: <span>Audio</span>,
								},
								{
									value: 'text',
									label: <span>Text</span>,
								},
								{
									value: 'audio_text',
									label: <span>Audio + Text</span>,
								},
							]}
						/>
					</FieldItem>
					<FieldItem label='Voice'>
						<Select
							onChange={setVoice}
							value={voice}
							options={[
								{
									value: 'Puck',
									label: <span>Puck</span>,
								},
								{
									value: 'Charon',
									label: <span>Charon</span>,
								},
								{
									value: 'Kore',
									label: <span>Kore</span>,
								},
								{
									value: 'Fenrir',
									label: <span>Fenrir</span>,
								},
								{
									value: 'Aoede',
									label: <span>Aoede</span>,
								},
							]}
						/>
					</FieldItem>
					<Collapse
						bordered={false}
						style={{ background: colorBgContainer }}
						activeKey={toolsPaneActive}
						onChange={(keys) =>
							setToolsPaneActive(keys as string[])
						}
						items={[
							{
								key: 'tools',
								label: 'Tools',
								children: (
									<Flex
										vertical
										gap={8}
										style={{
											paddingInlineStart: 24,
										}}
									>
										<FieldItem label='Grounding'>
												<Checkbox
													onChange={(e) => {
														if (tools) {
															setTools({
																...tools,
																grounding:
																	e.target
																		.checked,
															});
														}
													}}
													checked={tools?.grounding}
												/>
											</FieldItem>
												<FieldItem label='Speech to Text '>
									<Checkbox
										onChange={(e) => {
											const checked = e.target.checked;
											if (tools) {
												setTools({
													...tools,
													speechToText: checked,
												});
												setSpeechToTextEnabled(checked);
											}
										}}
										checked={tools?.speechToText}
										disabled={outPut !== 'audio_text'}
									/>
								</FieldItem>
									</Flex>
								),
								style: panelStyle,
							},
						]}
				/>
			</Flex>
		</Flex>

	</Layout>
);
};

export default LivePage;
