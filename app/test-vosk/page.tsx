'use client';
import React, { useState, useEffect, useRef } from 'react';
import { useVoskRecognition } from '@/vendor/hooks/use-vosk-recognition';
import { Button, Card, Typography, Space, Alert } from 'antd';

const { Title, Text } = Typography;

export default function TestVoskPage() {
  const [enabled, setEnabled] = useState(false);
  const [logs, setLogs] = useState<string[]>([]);
  const [isRecording, setIsRecording] = useState(false);
  const [hasPermission, setHasPermission] = useState<boolean | null>(null);
  
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const streamRef = useRef<MediaStream | null>(null);
  
  const addLog = (message: string) => {
    const timestamp = new Date().toLocaleTimeString();
    setLogs(prev => [...prev, `[${timestamp}] ${message}`]);
    console.log(`[${timestamp}] ${message}`);
  };
  
  const { isLoading, isReady, error, processAudioData } = useVoskRecognition({
    enabled,
    onResult: (text: string) => {
      addLog(`âœ… æœ€ç»ˆç»“æœ: ${text}`);
    },
    onPartialResult: (text: string) => {
      addLog(`ğŸ¤ éƒ¨åˆ†ç»“æœ: ${text}`);
    },
    onError: (error: string) => {
      addLog(`âŒ é”™è¯¯: ${error}`);
    }
  });
  
  useEffect(() => {
    addLog(`VoskçŠ¶æ€æ›´æ–°: isLoading=${isLoading}, isReady=${isReady}, error=${error}`);
  }, [isLoading, isReady, error]);
  
  // æ£€æŸ¥éº¦å…‹é£æƒé™
  useEffect(() => {
    const checkPermission = async () => {
      try {
        const result = await navigator.permissions.query({ name: 'microphone' as PermissionName });
        setHasPermission(result.state === 'granted');
        addLog(`éº¦å…‹é£æƒé™çŠ¶æ€: ${result.state}`);
      } catch (error) {
        addLog('æ— æ³•æ£€æŸ¥éº¦å…‹é£æƒé™');
      }
    };
    checkPermission();
  }, []);
  
  const handleToggle = () => {
    setEnabled(!enabled);
    addLog(`Vosk ${!enabled ? 'å¯ç”¨' : 'ç¦ç”¨'}`);
  };
  
  // è¯·æ±‚éº¦å…‹é£æƒé™
  const requestMicrophonePermission = async () => {
    try {
      addLog('è¯·æ±‚éº¦å…‹é£æƒé™...');
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        } 
      });
      setHasPermission(true);
      addLog('âœ… éº¦å…‹é£æƒé™è·å–æˆåŠŸ');
      // ç«‹å³åœæ­¢æµï¼Œåªæ˜¯ä¸ºäº†è·å–æƒé™
      stream.getTracks().forEach(track => track.stop());
    } catch (error) {
      setHasPermission(false);
      addLog(`âŒ éº¦å…‹é£æƒé™è·å–å¤±è´¥: ${error}`);
    }
  };
  
  // å¼€å§‹å½•éŸ³
  const startRecording = async () => {
    if (!hasPermission) {
      await requestMicrophonePermission();
      return;
    }
    
    try {
      addLog('ğŸ¤ å¼€å§‹å½•éŸ³...');
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        } 
      });
      
      streamRef.current = stream;
      audioChunksRef.current = [];
      
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      });
      
      mediaRecorderRef.current = mediaRecorder;
      
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
          addLog(`ğŸ“¦ æ”¶åˆ°éŸ³é¢‘æ•°æ®å—: ${event.data.size} bytes`);
        }
      };
      
      mediaRecorder.onstop = async () => {
        addLog('ğŸ›‘ å½•éŸ³åœæ­¢ï¼Œå¤„ç†éŸ³é¢‘æ•°æ®...');
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm;codecs=opus' });
        await processRecordedAudio(audioBlob);
      };
      
      mediaRecorder.start(1000); // æ¯1ç§’æ”¶é›†ä¸€æ¬¡æ•°æ®
      setIsRecording(true);
      addLog('âœ… å½•éŸ³å·²å¼€å§‹');
      
    } catch (error) {
      addLog(`âŒ å½•éŸ³å¤±è´¥: ${error}`);
    }
  };
  
  // åœæ­¢å½•éŸ³
  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      addLog('ğŸ›‘ åœæ­¢å½•éŸ³');
    }
    
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
  };
  
  // å¤„ç†å½•åˆ¶çš„éŸ³é¢‘
  const processRecordedAudio = async (audioBlob: Blob) => {
    try {
      addLog(`ğŸµ å¤„ç†éŸ³é¢‘æ–‡ä»¶: ${audioBlob.size} bytes`);
      
      // å°† Blob è½¬æ¢ä¸º ArrayBuffer
      const arrayBuffer = await audioBlob.arrayBuffer();
      addLog(`ğŸ“Š éŸ³é¢‘ ArrayBuffer: ${arrayBuffer.byteLength} bytes`);
      
      // åˆ›å»º AudioContext æ¥è§£ç éŸ³é¢‘
      const audioContext = new AudioContext({ sampleRate: 16000 });
      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
      
      addLog(`ğŸ¼ éŸ³é¢‘è§£ç æˆåŠŸ: ${audioBuffer.duration.toFixed(2)}ç§’, ${audioBuffer.sampleRate}Hz, ${audioBuffer.numberOfChannels}å£°é“`);
      
      // è·å–éŸ³é¢‘æ•°æ®ï¼ˆå•å£°é“ï¼‰
      const channelData = audioBuffer.getChannelData(0);
      addLog(`ğŸ“ˆ éŸ³é¢‘æ ·æœ¬æ•°: ${channelData.length}`);
      
      // è½¬æ¢ä¸º Int16Array (Vosk æœŸæœ›çš„æ ¼å¼)
      const int16Array = new Int16Array(channelData.length);
      for (let i = 0; i < channelData.length; i++) {
        // å°† float32 (-1.0 åˆ° 1.0) è½¬æ¢ä¸º int16 (-32768 åˆ° 32767)
        int16Array[i] = Math.max(-32768, Math.min(32767, channelData[i] * 32767));
      }
      
      addLog(`ğŸ”„ éŸ³é¢‘æ ¼å¼è½¬æ¢å®Œæˆ: Int16Array[${int16Array.length}]`);
      
      // å‘é€åˆ° Vosk
      if (isReady) {
        addLog('ğŸ“¤ å‘é€éŸ³é¢‘æ•°æ®åˆ° Vosk...');
        processAudioData(int16Array.buffer, audioBuffer.sampleRate);
      } else {
        addLog('âš ï¸ Vosk æœªå‡†å¤‡å¥½ï¼Œæ— æ³•å¤„ç†éŸ³é¢‘');
      }
      
      await audioContext.close();
      
    } catch (error) {
      addLog(`âŒ éŸ³é¢‘å¤„ç†å¤±è´¥: ${error}`);
    }
  };
  
  const testAudioData = () => {
    // åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•éŸ³é¢‘æ•°æ®
    const sampleRate = 16000;
    const duration = 1; // 1ç§’
    const samples = sampleRate * duration;
    const buffer = new ArrayBuffer(samples * 2); // 16ä½éŸ³é¢‘
    const view = new Int16Array(buffer);
    
    // ç”Ÿæˆä¸€ä¸ªç®€å•çš„æ­£å¼¦æ³¢
    for (let i = 0; i < samples; i++) {
      view[i] = Math.sin(2 * Math.PI * 440 * i / sampleRate) * 32767;
    }
    
    addLog('ğŸ“¤ å‘é€æµ‹è¯•éŸ³é¢‘æ•°æ®åˆ°Vosk');
    processAudioData(buffer, sampleRate);
  };

  // æµ‹è¯• Web Speech API ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
  const testWebSpeechAPI = () => {
    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      addLog('âŒ æµè§ˆå™¨ä¸æ”¯æŒ Web Speech API');
      return;
    }

    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
    const recognition = new SpeechRecognition();
    
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = 'en-US';
    
    recognition.onstart = () => {
      addLog('ğŸ¤ Web Speech API å¼€å§‹è¯†åˆ«...');
    };
    
    recognition.onresult = (event: any) => {
      let finalTranscript = '';
      let interimTranscript = '';
      
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript;
        if (event.results[i].isFinal) {
          finalTranscript += transcript;
        } else {
          interimTranscript += transcript;
        }
      }
      
      if (finalTranscript) {
        addLog(`âœ… Web Speech API æœ€ç»ˆç»“æœ: ${finalTranscript}`);
      }
      if (interimTranscript) {
        addLog(`ğŸ”„ Web Speech API ä¸´æ—¶ç»“æœ: ${interimTranscript}`);
      }
    };
    
    recognition.onerror = (event: any) => {
      addLog(`âŒ Web Speech API é”™è¯¯: ${event.error}`);
    };
    
    recognition.onend = () => {
      addLog('ğŸ›‘ Web Speech API è¯†åˆ«ç»“æŸ');
    };
    
    recognition.start();
    
    // 10ç§’åè‡ªåŠ¨åœæ­¢
    setTimeout(() => {
      recognition.stop();
    }, 10000);
  };
  
  const clearLogs = () => {
    setLogs([]);
    console.clear();
  };
  
  return (
    <div style={{ padding: '24px', maxWidth: '800px', margin: '0 auto' }}>
      <Title level={2}>Vosk è¯­éŸ³è¯†åˆ«æµ‹è¯•</Title>
      
      <Space direction="vertical" size="large" style={{ width: '100%' }}>
        <Card title="æ§åˆ¶é¢æ¿">
          <Space direction="vertical" style={{ width: '100%' }}>
            <Space>
              <Button 
                type={enabled ? "primary" : "default"}
                onClick={handleToggle}
              >
                {enabled ? 'ç¦ç”¨ Vosk' : 'å¯ç”¨ Vosk'}
              </Button>
              
              <Button 
                 onClick={testAudioData}
                 disabled={!isReady}
               >
                 æµ‹è¯•éŸ³é¢‘æ•°æ®
               </Button>
               
               <Button 
                 onClick={testWebSpeechAPI}
               >
                 æµ‹è¯• Web Speech API
               </Button>
               
               <Button 
                 onClick={clearLogs}
               >
                 æ¸…ç©ºæ—¥å¿—
               </Button>
             </Space>
            
            <Space>
              {hasPermission === null && (
                <Button onClick={requestMicrophonePermission}>
                  æ£€æŸ¥éº¦å…‹é£æƒé™
                </Button>
              )}
              
              {hasPermission === false && (
                <Button type="primary" onClick={requestMicrophonePermission}>
                  è¯·æ±‚éº¦å…‹é£æƒé™
                </Button>
              )}
              
              {hasPermission === true && (
                <>
                  <Button 
                     type="primary"
                     danger={isRecording}
                     onClick={isRecording ? stopRecording : startRecording}
                     disabled={!isReady}
                   >
                     {isRecording ? 'ğŸ›‘ åœæ­¢å½•éŸ³' : 'ğŸ¤ å¼€å§‹å½•éŸ³'}
                   </Button>
                </>
              )}
            </Space>
          </Space>
        </Card>
        
        <Card title="çŠ¶æ€ä¿¡æ¯">
          <Space direction="vertical">
            <Text>Voskå¯ç”¨çŠ¶æ€: {enabled ? 'âœ… å·²å¯ç”¨' : 'âŒ å·²ç¦ç”¨'}</Text>
            <Text>VoskåŠ è½½çŠ¶æ€: {isLoading ? 'ğŸ”„ åŠ è½½ä¸­...' : 'âœ… åŠ è½½å®Œæˆ'}</Text>
            <Text>Voskå‡†å¤‡çŠ¶æ€: {isReady ? 'âœ… å·²å‡†å¤‡' : 'âŒ æœªå‡†å¤‡'}</Text>
            <Text>éº¦å…‹é£æƒé™: {
              hasPermission === null ? 'ğŸ” æ£€æŸ¥ä¸­...' :
              hasPermission ? 'âœ… å·²æˆæƒ' : 'âŒ æœªæˆæƒ'
            }</Text>
            <Text>å½•éŸ³çŠ¶æ€: {isRecording ? 'ğŸ¤ å½•éŸ³ä¸­...' : 'â¹ï¸ å·²åœæ­¢'}</Text>
            {error && <Alert message={error} type="error" />}
          </Space>
        </Card>
        
        <Card title="æ—¥å¿—è¾“å‡º" style={{ height: '400px', overflow: 'auto' }}>
          <div style={{ fontFamily: 'monospace', fontSize: '12px' }}>
            {logs.map((log, index) => (
              <div key={index} style={{ marginBottom: '4px' }}>
                {log}
              </div>
            ))}
          </div>
        </Card>
      </Space>
    </div>
  );
}