/**
 * å¯¹è¯å½•åˆ¶å™¨ - åŒæ—¶å½•åˆ¶éº¦å…‹é£è¾“å…¥å’ŒAPIéŸ³é¢‘è¾“å‡º
 * æ”¯æŒç”Ÿæˆæ—¶é—´åŒæ­¥çš„MP3æ–‡ä»¶
 */

import EventEmitter from "eventemitter3";
import { audioContext } from "./utils";

export interface AudioChunk {
  data: Float32Array;
  timestamp: number; // è·ç¦»å½•åˆ¶å¼€å§‹çš„æ¯«ç§’æ•°
  source: 'microphone' | 'api';
  sampleRate: number;
}

export interface RecordingOptions {
  micSampleRate?: number;
  apiSampleRate?: number;
  outputSampleRate?: number;
}

export interface RecordingUrls {
  micUrl: string;
  apiUrl: string;
  mixedUrl: string;
}

export class ConversationRecorder extends EventEmitter {
  private isRecording = false;
  private startTime = 0;
  private micAudioChunks: AudioChunk[] = [];
  private apiAudioChunks: AudioChunk[] = [];
  private micStream: MediaStream | null = null;
  private micAudioContext: AudioContext | null = null;
  private micSource: MediaStreamAudioSourceNode | null = null;
  private micProcessor: ScriptProcessorNode | null = null;
  private options: Required<RecordingOptions>;

  constructor(options: RecordingOptions = {}) {
    super();
    this.options = {
      micSampleRate: options.micSampleRate || 16000,
      apiSampleRate: options.apiSampleRate || 24000,
      outputSampleRate: options.outputSampleRate || 44100
    };
  }

  /**
   * å¼€å§‹å½•åˆ¶å¯¹è¯
   */
  async startRecording(): Promise<void> {
    if (this.isRecording) {
      throw new Error('å½•åˆ¶å·²åœ¨è¿›è¡Œä¸­');
    }

    try {
      // æ¸…ç©ºä¹‹å‰çš„å½•åˆ¶æ•°æ®
      this.micAudioChunks = [];
      this.apiAudioChunks = [];
      this.startTime = Date.now();
      
      // åˆå§‹åŒ–éº¦å…‹é£å½•åˆ¶
      await this.initMicrophoneRecording();
      
      this.isRecording = true;
      this.emit('recording-started');
      
      console.log('ğŸ™ï¸ å¯¹è¯å½•åˆ¶å·²å¼€å§‹');
    } catch (error) {
      console.error('âŒ å¯åŠ¨å½•åˆ¶å¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * åœæ­¢å½•åˆ¶å¹¶ç”ŸæˆéŸ³é¢‘æ–‡ä»¶
   */
  async stopRecording(): Promise<RecordingUrls> {
    if (!this.isRecording) {
      throw new Error('å½“å‰æ²¡æœ‰è¿›è¡Œå½•åˆ¶');
    }

    this.isRecording = false;
    
    // åœæ­¢éº¦å…‹é£å½•åˆ¶
    this.stopMicrophoneRecording();
    
    console.log('ğŸ™ï¸ å¯¹è¯å½•åˆ¶å·²åœæ­¢');
    console.log(`ğŸ“Š å½•åˆ¶ç»Ÿè®¡: éº¦å…‹é£ç‰‡æ®µ ${this.micAudioChunks.length}, APIç‰‡æ®µ ${this.apiAudioChunks.length}`);
    
    // ç”ŸæˆéŸ³é¢‘æ–‡ä»¶
    const urls = await this.generateAudioFiles();
    
    this.emit('recording-stopped', urls);
    return urls;
  }

  /**
   * æ·»åŠ éº¦å…‹é£éŸ³é¢‘æ•°æ®ï¼ˆæŒ‰æ•è·æ—¶é—´å†™å…¥æ—¶é—´è½´ï¼‰
   */
  addMicrophoneAudio(audioData: Float32Array, sampleRate: number = this.options.micSampleRate): void {
    if (!this.isRecording) return;
    
    const chunk: AudioChunk = {
      data: new Float32Array(audioData),
      timestamp: Date.now() - this.startTime,
      source: 'microphone',
      sampleRate
    };
    
    this.micAudioChunks.push(chunk);
  }

  /**
   * æ·»åŠ APIéŸ³é¢‘æ•°æ®ï¼ˆä½¿ç”¨æ•è·æ—¶é—´ä½œä¸ºæ—¶é—´æˆ³ï¼‰
   * æ³¨æ„ï¼šå¦‚æœå¯ç”¨ï¼Œè¯·ä¼˜å…ˆä½¿ç”¨ addApiAudioWithTimestamp ä¼ å…¥å®é™…æ’­æ”¾çš„è°ƒåº¦æ—¶é—´
   */
  addApiAudio(audioData: Float32Array, sampleRate: number = this.options.apiSampleRate): void {
    if (!this.isRecording) return;
    
    const chunk: AudioChunk = {
      data: new Float32Array(audioData),
      timestamp: Date.now() - this.startTime,
      source: 'api',
      sampleRate
    };
    
    this.apiAudioChunks.push(chunk);
  }

  /**
   * æ·»åŠ APIéŸ³é¢‘æ•°æ®ï¼ˆä½¿ç”¨å®é™…æ’­æ”¾è°ƒåº¦æ—¶é—´çš„æ—¶é—´æˆ³ï¼Œæ¯«ç§’ï¼‰
   */
  addApiAudioWithTimestamp(audioData: Float32Array, sampleRate: number, timestampMs: number): void {
    if (!this.isRecording) return;

    const ts = Math.max(0, timestampMs); // ä¸å…è®¸è´Ÿæ•°
    const chunk: AudioChunk = {
      data: new Float32Array(audioData),
      timestamp: ts,
      source: 'api',
      sampleRate
    };

    this.apiAudioChunks.push(chunk);
  }

  /**
   * åˆå§‹åŒ–éº¦å…‹é£å½•åˆ¶
   */
  private async initMicrophoneRecording(): Promise<void> {
    try {
      // è·å–éº¦å…‹é£æƒé™
      this.micStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: this.options.micSampleRate,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        }
      });

      // åˆ›å»ºéŸ³é¢‘ä¸Šä¸‹æ–‡
      this.micAudioContext = await audioContext({ sampleRate: this.options.micSampleRate });
      this.micSource = this.micAudioContext.createMediaStreamSource(this.micStream);
      
      // åˆ›å»ºéŸ³é¢‘å¤„ç†å™¨
      this.micProcessor = this.micAudioContext.createScriptProcessor(4096, 1, 1);
      
      this.micProcessor.onaudioprocess = (event) => {
        if (!this.isRecording) return;
        
        const inputBuffer = event.inputBuffer;
        const inputData = inputBuffer.getChannelData(0);
        
        // æ·»åŠ åˆ°å½•åˆ¶ç¼“å†²åŒº
        this.addMicrophoneAudio(inputData, this.options.micSampleRate);
      };
      
      // è¿æ¥éŸ³é¢‘èŠ‚ç‚¹
      this.micSource.connect(this.micProcessor);
      this.micProcessor.connect(this.micAudioContext.destination);
      
    } catch (error) {
      console.error('âŒ åˆå§‹åŒ–éº¦å…‹é£å½•åˆ¶å¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * åœæ­¢éº¦å…‹é£å½•åˆ¶
   */
  private stopMicrophoneRecording(): void {
    if (this.micProcessor) {
      this.micProcessor.disconnect();
      this.micProcessor = null;
    }
    
    if (this.micSource) {
      this.micSource.disconnect();
      this.micSource = null;
    }
    
    if (this.micStream) {
      this.micStream.getTracks().forEach(track => track.stop());
      this.micStream = null;
    }
    
    if (this.micAudioContext) {
      this.micAudioContext.close();
      this.micAudioContext = null;
    }
  }

  /**
   * ç”ŸæˆéŸ³é¢‘æ–‡ä»¶
   */
  private async generateAudioFiles(): Promise<RecordingUrls> {
    const outputSampleRate = this.options.outputSampleRate;
    
    // ç”Ÿæˆå•ç‹¬çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆæ³¨æ„ï¼šä¿æŒä¸å…¨å±€å¼€å§‹æ—¶é—´å¯¹é½ï¼Œä¸å†å¯¹é½åˆ°å„è‡ªé¦–å—ï¼‰
    const micBuffer = this.createAudioBuffer(this.micAudioChunks, outputSampleRate);
    const apiBuffer = this.createAudioBuffer(this.apiAudioChunks, outputSampleRate);
    
    // ç”Ÿæˆæ··åˆéŸ³é¢‘æ–‡ä»¶ï¼ˆåŒä¸€æ—¶é—´è½´ä¸Šé€æ ·æœ¬æ··åˆï¼‰
    const mixedBuffer = this.mixAudioBuffers(micBuffer, apiBuffer, outputSampleRate);
    
    // è½¬æ¢ä¸ºWAVæ ¼å¼å¹¶åˆ›å»ºURL
    const micUrl = this.createAudioUrl(micBuffer, outputSampleRate);
    const apiUrl = this.createAudioUrl(apiBuffer, outputSampleRate);
    const mixedUrl = this.createAudioUrl(mixedBuffer, outputSampleRate);
    
    return { micUrl, apiUrl, mixedUrl };
  }

  /**
   * åˆ›å»ºæ—¶é—´åŒæ­¥çš„éŸ³é¢‘ç¼“å†²åŒº
   * ä½¿ç”¨â€œå½•åˆ¶å¼€å§‹â€ä¸ºé›¶ç‚¹çš„å…¨å±€æ—¶é—´è½´
   */
  private createAudioBuffer(chunks: AudioChunk[], targetSampleRate: number): Float32Array {
    if (chunks.length === 0) {
      console.log(`âš ï¸ æ²¡æœ‰éŸ³é¢‘æ•°æ®`);
      return new Float32Array(0);
    }
    
    // æŒ‰æ—¶é—´æˆ³æ’åºï¼ˆæ¯«ç§’ï¼‰
    const sortedChunks = chunks.sort((a, b) => a.timestamp - b.timestamp);
    
    // è®¡ç®—å½•åˆ¶æ€»æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰ï¼Œä»¥â€œæœ€åä¸€å—çš„ç»“æŸæ—¶é—´â€ä¸ºå‡†
    let endTimeMs = 0;
    for (const c of sortedChunks) {
      const cEnd = c.timestamp + (c.data.length / c.sampleRate) * 1000;
      if (cEnd > endTimeMs) endTimeMs = cEnd;
    }
    const durationSec = Math.max(endTimeMs / 1000, 0.1); // è‡³å°‘0.1ç§’
    
    // è®¡ç®—è¾“å‡ºç¼“å†²åŒºå¤§å°
    const totalSamples = Math.ceil(durationSec * targetSampleRate);
    const buffer = new Float32Array(totalSamples);
    
    console.log(`ğŸ“Š éŸ³é¢‘å¤„ç†: ${sortedChunks.length} å—, æ—¶é•¿ ${durationSec.toFixed(2)}s, è¾“å‡ºæ ·æœ¬ ${totalSamples}`);
    
    // å°†æ¯ä¸ªéŸ³é¢‘ç‰‡æ®µæ”¾ç½®åˆ°å…¨å±€æ—¶é—´è½´çš„æ­£ç¡®ä½ç½®
    for (const chunk of sortedChunks) {
      const relativeTimeSec = Math.max(0, chunk.timestamp / 1000); // ç›¸å¯¹å…¨å±€é›¶ç‚¹ï¼ˆç§’ï¼‰
      const startSample = Math.floor(relativeTimeSec * targetSampleRate);
      
      // é‡é‡‡æ ·éŸ³é¢‘æ•°æ®åˆ°è¾“å‡ºé‡‡æ ·ç‡
      const resampledData = this.resampleAudio(chunk.data, chunk.sampleRate, targetSampleRate);
      
      // ç¡®ä¿ä¸è¶…å‡ºç¼“å†²åŒºè¾¹ç•Œ
      const endSample = Math.min(startSample + resampledData.length, totalSamples);
      const copyLength = endSample - startSample;
      
      if (copyLength > 0) {
        // æ··åˆéŸ³é¢‘ï¼ˆå¦‚æœæœ‰é‡å ï¼‰
        for (let i = 0; i < copyLength; i++) {
          buffer[startSample + i] += resampledData[i];
        }
      }
    }
    
    // æ ‡å‡†åŒ–éŸ³é¢‘ä»¥é˜²æ­¢å‰Šæ³¢
    this.normalizeAudio(buffer);
    
    return buffer;
  }

  /**
   * æ··åˆä¸¤ä¸ªéŸ³é¢‘ç¼“å†²åŒº
   */
  private mixAudioBuffers(buffer1: Float32Array, buffer2: Float32Array, sampleRate: number): Float32Array {
    const maxLength = Math.max(buffer1.length, buffer2.length);
    const mixedBuffer = new Float32Array(maxLength);
    
    // è®¡ç®—éŸ³é¢‘èƒ½é‡ä»¥è°ƒæ•´æ··åˆæ¯”ä¾‹
    const micEnergy = this.calculateRMS(buffer1);
    const apiEnergy = this.calculateRMS(buffer2);
    
    // åŠ¨æ€è°ƒæ•´æ··åˆæ¯”ä¾‹ï¼Œç¡®ä¿ä¸¤ä¸ªå£°é“éƒ½æ¸…æ™°å¯å¬
    let micGain = 0.7;
    let apiGain = 0.7;
    
    if (micEnergy > 0 && apiEnergy > 0) {
      const energyRatio = micEnergy / apiEnergy;
      if (energyRatio > 2) {
        // éº¦å…‹é£éŸ³é‡è¾ƒå¤§ï¼Œé™ä½å…¶å¢ç›Š
        micGain = 0.5;
        apiGain = 0.8;
      } else if (energyRatio < 0.5) {
        // APIéŸ³é¢‘è¾ƒå¤§ï¼Œé™ä½å…¶å¢ç›Š
        micGain = 0.8;
        apiGain = 0.5;
      }
    }
    
    for (let i = 0; i < maxLength; i++) {
      const sample1 = i < buffer1.length ? buffer1[i] * micGain : 0;
      const sample2 = i < buffer2.length ? buffer2[i] * apiGain : 0;
      
      // æ··åˆéŸ³é¢‘
      mixedBuffer[i] = sample1 + sample2;
    }
    
    // æ ‡å‡†åŒ–æ··åˆåçš„éŸ³é¢‘
    this.normalizeAudio(mixedBuffer);
    
    console.log(`ğŸ“Š æ··åˆéŸ³é¢‘: éº¦å…‹é£å¢ç›Š=${micGain.toFixed(2)}, APIå¢ç›Š=${apiGain.toFixed(2)}, æ ·æœ¬=${maxLength}`);
    return mixedBuffer;
  }

  /**
   * é‡é‡‡æ ·éŸ³é¢‘æ•°æ®ï¼ˆä½¿ç”¨çº¿æ€§æ’å€¼ï¼‰
   */
  private resampleAudio(inputData: Float32Array, inputSampleRate: number, outputSampleRate: number): Float32Array {
    if (inputSampleRate === outputSampleRate) {
      return inputData;
    }
    
    const ratio = outputSampleRate / inputSampleRate;
    const outputLength = Math.floor(inputData.length * ratio);
    const outputData = new Float32Array(outputLength);
    
    for (let i = 0; i < outputLength; i++) {
      const inputIndex = i / ratio;
      const inputIndexFloor = Math.floor(inputIndex);
      const inputIndexCeil = Math.min(inputIndexFloor + 1, inputData.length - 1);
      const fraction = inputIndex - inputIndexFloor;
      
      // çº¿æ€§æ’å€¼
      outputData[i] = inputData[inputIndexFloor] * (1 - fraction) + inputData[inputIndexCeil] * fraction;
    }
    
    return outputData;
  }
  
  /**
   * è®¡ç®—éŸ³é¢‘çš„RMSï¼ˆå‡æ–¹æ ¹ï¼‰èƒ½é‡
   */
  private calculateRMS(buffer: Float32Array): number {
    if (buffer.length === 0) return 0;
    
    let sum = 0;
    for (let i = 0; i < buffer.length; i++) {
      sum += buffer[i] * buffer[i];
    }
    
    return Math.sqrt(sum / buffer.length);
  }
  
  /**
   * æ ‡å‡†åŒ–éŸ³é¢‘ä»¥é˜²æ­¢å‰Šæ³¢
   */
  private normalizeAudio(buffer: Float32Array): void {
    if (buffer.length === 0) return;
    
    // æ‰¾åˆ°æœ€å¤§ç»å¯¹å€¼
    let maxValue = 0;
    for (let i = 0; i < buffer.length; i++) {
      maxValue = Math.max(maxValue, Math.abs(buffer[i]));
    }
    
    // å¦‚æœéŸ³é¢‘è¿‡å¤§ï¼Œè¿›è¡Œæ ‡å‡†åŒ–
    if (maxValue > 0.95) {
      const scale = 0.95 / maxValue;
      for (let i = 0; i < buffer.length; i++) {
        buffer[i] *= scale;
      }
      console.log(`ğŸ”§ éŸ³é¢‘æ ‡å‡†åŒ–: ç¼©æ”¾æ¯”ä¾‹ ${scale.toFixed(3)}`);
    }
  }

  /**
   * åˆ›å»ºéŸ³é¢‘URL
   */
  private createAudioUrl(audioBuffer: Float32Array, sampleRate: number): string {
    const wavBuffer = this.encodeWAV(audioBuffer, sampleRate);
    const blob = new Blob([wavBuffer], { type: 'audio/wav' });
    return URL.createObjectURL(blob);
  }

  /**
   * ç¼–ç ä¸ºWAVæ ¼å¼
   */
  private encodeWAV(audioBuffer: Float32Array, sampleRate: number): ArrayBuffer {
    const length = audioBuffer.length;
    const buffer = new ArrayBuffer(44 + length * 2);
    const view = new DataView(buffer);
    
    // WAVæ–‡ä»¶å¤´
    const writeString = (offset: number, string: string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    };
    
    // RIFFå¤´
    writeString(0, 'RIFF');
    view.setUint32(4, 36 + length * 2, true); // æ–‡ä»¶å¤§å°
    writeString(8, 'WAVE');
    
    // fmtå—
    writeString(12, 'fmt ');
    view.setUint32(16, 16, true); // fmtå—å¤§å°
    view.setUint16(20, 1, true); // éŸ³é¢‘æ ¼å¼ (PCM)
    view.setUint16(22, 1, true); // å£°é“æ•° (å•å£°é“)
    view.setUint32(24, sampleRate, true); // é‡‡æ ·ç‡
    view.setUint32(28, sampleRate * 2, true); // å­—èŠ‚ç‡
    view.setUint16(32, 2, true); // å—å¯¹é½
    view.setUint16(34, 16, true); // ä½æ·±åº¦
    
    // dataå—
    writeString(36, 'data');
    view.setUint32(40, length * 2, true); // æ•°æ®å¤§å°
    
    // è½¬æ¢ä¸º16ä½PCMæ•°æ®
    let offset = 44;
    for (let i = 0; i < length; i++) {
      // é™åˆ¶èŒƒå›´å¹¶è½¬æ¢ä¸º16ä½æ•´æ•°
      const sample = Math.max(-1, Math.min(1, audioBuffer[i]));
      view.setInt16(offset, sample * 0x7FFF, true);
      offset += 2;
    }
    
    return buffer;
  }

  /**
   * æ¸…ç†èµ„æº
   */
  dispose(): void {
    if (this.isRecording) {
      this.stopMicrophoneRecording();
    }
    
    this.micAudioChunks = [];
    this.apiAudioChunks = [];
    this.removeAllListeners();
  }

  /**
   * è·å–å½•åˆ¶çŠ¶æ€
   */
  get recording(): boolean {
    return this.isRecording;
  }

  /**
   * è·å–å½•åˆ¶æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
   */
  get duration(): number {
    return this.isRecording ? Date.now() - this.startTime : 0;
  }
}