import { useEffect, useRef, useState, useCallback } from 'react';
import { nanoid } from 'nanoid'

export interface UseVoskRecognitionOptions {
  enabled: boolean;
  serviceUrl?: string;
  onResult?: (text: string) => void;
  onPartialResult?: (text: string) => void;
  onError?: (error: string) => void;
}

export function useVoskRecognition({
  enabled,
  serviceUrl = 'http://localhost:5001',
  onResult,
  onPartialResult,
  onError,
}: UseVoskRecognitionOptions) {
  console.log('ğŸ¤ useVoskRecognition åˆå§‹åŒ–:', { enabled, serviceUrl });
  console.log('ğŸ¤ useVoskRecognition å‚æ•°è¯¦æƒ…:', { 
    enabled, 
    serviceUrl, 
    hasOnResult: !!onResult, 
    hasOnPartialResult: !!onPartialResult, 
    hasOnError: !!onError 
  });
  
  // å¼ºåˆ¶è¾“å‡ºåˆ°window.consoleç¡®ä¿æ—¥å¿—å¯è§
  if (typeof window !== 'undefined') {
    window.console.log('ğŸ¤ [VOSK] useVoskRecognition åˆå§‹åŒ–:', { enabled, serviceUrl });
  }
  
  const [isLoading, setIsLoading] = useState(false);
  const [isReady, setIsReady] = useState(false);
  const [error, setError] = useState<string | null>(null);
  
  const audioContextRef = useRef<AudioContext | null>(null);
  // ä¸ºä¸€æ¬¡å¯¹è¯ï¼ˆturnï¼‰ç»´æŒä¸€ä¸ªä¼šè¯IDï¼Œä¾›åç«¯æŒ‰ä¼šè¯ç´¯ç§¯è¯†åˆ«å¹¶åœ¨ç»“æŸæ—¶è¾“å‡º FinalResult
  const sessionIdRef = useRef<string | null>(null);
  const flushingRef = useRef<boolean>(false);
  const ensureSessionId = () => {
    if (!sessionIdRef.current) {
      sessionIdRef.current = nanoid();
      console.log('ğŸ†• [VOSK] åˆ›å»ºæ–°çš„ä¼šè¯ID:', sessionIdRef.current);
    }
    return sessionIdRef.current;
  }
  
  // æ£€æŸ¥ Python æœåŠ¡å¥åº·çŠ¶æ€
  const checkServiceHealth = useCallback(async () => {
    if (!enabled) return false;
    
    try {
      console.log('ğŸ” æ£€æŸ¥ Python Vosk æœåŠ¡å¥åº·çŠ¶æ€...');
      const response = await fetch(`${serviceUrl}/health`);
      
      if (!response.ok) {
        throw new Error(`æœåŠ¡å“åº”é”™è¯¯: ${response.status}`);
      }
      
      const data = await response.json();
      console.log('âœ… Python Vosk æœåŠ¡çŠ¶æ€:', data);
      
      if (data.status === 'ok' && data.model_loaded) {
        console.log('âœ… Python Vosk æœåŠ¡å‡†å¤‡å°±ç»ª');
        return true;
      } else {
        throw new Error('Python Vosk æœåŠ¡æ¨¡å‹æœªåŠ è½½');
      }
    } catch (err) {
      const errorMsg = `Python Vosk æœåŠ¡è¿æ¥å¤±è´¥: ${err instanceof Error ? err.message : String(err)}`;
      console.error('âŒ', errorMsg);
      setError(errorMsg);
      if (onError) {
        onError(errorMsg);
      }
      return false;
    }
  }, [enabled, serviceUrl, onError]);
  
  // åˆå§‹åŒ–æœåŠ¡è¿æ¥
  const initializeService = useCallback(async () => {
    if (!enabled) return;
    
    try {
      console.log('ğŸ¤ å¼€å§‹åˆå§‹åŒ– Python Vosk æœåŠ¡è¿æ¥...');
      setIsLoading(true);
      setError(null);
      
      const isHealthy = await checkServiceHealth();
      
      if (isHealthy) {
        setIsReady(true);
        setIsLoading(false);
        console.log('ğŸš€ Python Vosk æœåŠ¡åˆå§‹åŒ–å®Œæˆï¼Œå‡†å¤‡æ¥æ”¶éŸ³é¢‘æ•°æ®');
      } else {
        setIsLoading(false);
      }
      
    } catch (err) {
      const errorMsg = `Failed to initialize Python Vosk service: ${err instanceof Error ? err.message : String(err)}`;
      setError(errorMsg);
      setIsLoading(false);
      if (onError) {
        onError(errorMsg);
      }
    }
  }, [enabled, checkServiceHealth, onError]);
  
  // å¤„ç†éŸ³é¢‘æ•°æ®
  const processAudioData = useCallback(async (audioData: ArrayBuffer, sampleRate: number = 16000) => {
    console.log('ğŸ¤ processAudioData è¢«è°ƒç”¨:', { 
      isReady, 
      bufferSize: audioData.byteLength,
      sampleRate 
    });
    
    if (!isReady) {
      console.log('âš ï¸ Python Vosk æœåŠ¡æœªå‡†å¤‡å¥½:', { isReady });
      return;
    }
    const sessionId = ensureSessionId();
    
    try {
      console.log('ğŸµ å¤„ç†éŸ³é¢‘æ•°æ®:', { dataLength: audioData.byteLength, sampleRate });
      
      // åˆ›å»º AudioContextï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
      if (!audioContextRef.current) {
        audioContextRef.current = new AudioContext({ sampleRate: 16000 }); // Voskæ¨¡å‹éœ€è¦16000Hz
        console.log('ğŸ”Š åˆ›å»º AudioContextï¼Œé‡‡æ ·ç‡: 16000Hz');
      }
      
      // å°† ArrayBuffer è½¬æ¢ä¸º Float32Array
      const int16Array = new Int16Array(audioData);
      let float32Array = new Float32Array(int16Array.length);
      
      // å°† Int16 è½¬æ¢ä¸º Float32 (-1.0 åˆ° 1.0 èŒƒå›´)
      for (let i = 0; i < int16Array.length; i++) {
        float32Array[i] = int16Array[i] / 32768.0;
      }
      
      // å¦‚æœè¾“å…¥é‡‡æ ·ç‡ä¸æ˜¯16000Hzï¼Œéœ€è¦é‡é‡‡æ ·
      if (sampleRate !== 16000) {
        console.log(`ğŸ”„ é‡é‡‡æ ·: ${sampleRate}Hz -> 16000Hz`);
        const targetSampleRate = 16000;
        const resampleRatio = targetSampleRate / sampleRate; // ä¿®å¤ï¼šæ­£ç¡®çš„é‡é‡‡æ ·æ¯”ä¾‹
        const resampledLength = Math.floor(float32Array.length * resampleRatio);
        const resampledArray = new Float32Array(resampledLength);
        
        console.log(`ğŸ”§ é‡é‡‡æ ·å‚æ•°: æ¯”ä¾‹=${resampleRatio.toFixed(4)}, åŸå§‹é•¿åº¦=${float32Array.length}, ç›®æ ‡é•¿åº¦=${resampledLength}`);
        
        // æ”¹è¿›çš„çº¿æ€§æ’å€¼é‡é‡‡æ ·
        for (let i = 0; i < resampledLength; i++) {
          const sourceIndex = i / resampleRatio; // åœ¨æºæ•°ç»„ä¸­çš„ä½ç½®
          const index = Math.floor(sourceIndex);
          const fraction = sourceIndex - index;
          
          if (index + 1 < float32Array.length) {
            resampledArray[i] = float32Array[index] * (1 - fraction) + float32Array[index + 1] * fraction;
          } else if (index < float32Array.length) {
            resampledArray[i] = float32Array[index];
          } else {
            resampledArray[i] = 0; // é˜²æ­¢è¶Šç•Œ
          }
        }
        
        float32Array = resampledArray;
        console.log('ğŸ”„ é‡é‡‡æ ·å®Œæˆ:', { 
          originalSamples: int16Array.length, 
          resampledSamples: float32Array.length,
          originalSampleRate: sampleRate,
          targetSampleRate: targetSampleRate,
          resampleRatio: resampleRatio.toFixed(4)
        });
      } else {
         console.log('ğŸ”„ éŸ³é¢‘æ•°æ®è½¬æ¢å®Œæˆ:', { 
           originalSamples: int16Array.length, 
           convertedSamples: float32Array.length,
           sampleRange: `${Math.min(...Array.from(float32Array))} to ${Math.max(...Array.from(float32Array))}`
         });
      }
      
      // å‘é€ Float32Array åˆ° Python Vosk æœåŠ¡
      console.log('ğŸ“¤ å‘é€éŸ³é¢‘æ•°æ®åˆ° Python Vosk æœåŠ¡');
      
      const response = await fetch(`${serviceUrl}/recognize_stream`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/octet-stream',
          'X-Session-Id': sessionId,
        },
        body: float32Array.buffer
      });
      
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }
      
      const result = await response.json();
      console.log('ğŸ¤ Python Vosk è¯†åˆ«ç»“æœ:', result);
      
      if (result.success) {
        if (result.type === 'final' && result.text && result.text.trim()) {
          console.log('ğŸ¯ æœ€ç»ˆè¯†åˆ«ç»“æœ:', result.text);
          if (onResult) {
            onResult(result.text.trim());
          }
          // turn ç»“æŸåé‡ç½®ä¼šè¯ï¼Œç­‰å¾…ä¸‹ä¸€ä¸ª turn
          sessionIdRef.current = null;
        } else if (result.type === 'partial' && result.text && result.text.trim()) {
          console.log('ğŸ¤ éƒ¨åˆ†è¯†åˆ«ç»“æœ:', result.text);
          if (onPartialResult) {
            onPartialResult(result.text.trim());
          }
        }
      } else {
        throw new Error(result.error || 'è¯†åˆ«å¤±è´¥');
      }
      
    } catch (err) {
      const errorMsg = `Audio processing error: ${err instanceof Error ? err.message : String(err)}`;
      console.error('âŒ Python Vosk å¤„ç†éŸ³é¢‘æ•°æ®é”™è¯¯:', err);
      setError(errorMsg);
      if (onError) {
        onError(errorMsg);
      }
    }
  }, [isReady, serviceUrl, onResult, onPartialResult, onError]);

  // ç»“æŸå½“å‰ä¼šè¯ï¼ˆä¸€ä¸ª turnï¼‰ï¼Œè§¦å‘åç«¯ FinalResult
  const flush = useCallback(async () => {
    if (!isReady) return;
    if (flushingRef.current) return; // é˜²æŠ–ï¼šé¿å…é‡å¤è§¦å‘
    const sessionId = sessionIdRef.current;
    if (!sessionId) {
      console.log('â„¹ï¸ [VOSK] å½“å‰æ— ä¼šè¯éœ€è¦ç»“æŸ');
      return;
    }
    try {
      console.log('ğŸ§¹ è§¦å‘ä¼šè¯ç»“æŸï¼Œè·å– FinalResult:', sessionId);
      flushingRef.current = true;
      const resp = await fetch(`${serviceUrl}/recognize_stream`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/octet-stream',
          'X-Session-Id': sessionId,
          'X-End-Of-Utterance': '1',
        },
        // å…è®¸ç©ºbody
        body: new Uint8Array(0),
      });
      if (!resp.ok) {
        throw new Error(`HTTP ${resp.status}: ${resp.statusText}`);
      }
      const res = await resp.json();
      console.log('ğŸ§¾ ä¼šè¯æœ€ç»ˆç»“æœ:', res);
      if (res?.success && res?.type === 'final' && typeof res.text === 'string') {
        const text = (res.text as string).trim();
        if (text && onResult) onResult(text);
      }
    } catch (e) {
      const msg = `Flush error: ${e instanceof Error ? e.message : String(e)}`;
      console.warn('âš ï¸ Vosk ä¼šè¯ç»“æŸé”™è¯¯:', e);
      if (onError) onError(msg);
    } finally {
      flushingRef.current = false;
      sessionIdRef.current = null; // ä¸‹ä¸€æ¬¡ turn é‡æ–°ç”Ÿæˆ
    }
  }, [isReady, serviceUrl, onResult, onError]);
  
  // æ¸…ç†èµ„æº
  const cleanup = useCallback(() => {
    if (audioContextRef.current) {
      try {
        audioContextRef.current.close();
      } catch (e) {
        // å¿½ç•¥æ¸…ç†é”™è¯¯
      }
      audioContextRef.current = null;
    }
    
    setIsReady(false);
    setError(null);
    sessionIdRef.current = null;
  }, []);
  
  // é‡ç½®è¯†åˆ«å™¨
  const resetRecognizer = useCallback(async () => {
    if (!isReady) return;
    
    try {
      console.log('ğŸ”„ é‡ç½® Python Vosk è¯†åˆ«å™¨...');
      const response = await fetch(`${serviceUrl}/reset`, {
        method: 'POST'
      });
      
      if (response.ok) {
        console.log('âœ… Python Vosk è¯†åˆ«å™¨å·²é‡ç½®');
      } else {
        console.warn('âš ï¸ é‡ç½®è¯†åˆ«å™¨å¤±è´¥');
      }
    } catch (err) {
      console.warn('âš ï¸ é‡ç½®è¯†åˆ«å™¨é”™è¯¯:', err);
    }
  }, [isReady, serviceUrl]);
  
  // åˆå§‹åŒ–æ•ˆæœ
  useEffect(() => {
    console.log('ğŸ¤ useVoskRecognition useEffect è§¦å‘:', { enabled, serviceUrl });
    if (enabled && !isReady && !isLoading) {
      console.log('ğŸ¤ å¼€å§‹åˆå§‹åŒ– Python Vosk æœåŠ¡');
      initializeService();
    } else if (!enabled) {
      console.log('ğŸ¤ Python Vosk æœåŠ¡å·²ç¦ç”¨ï¼Œè·³è¿‡åˆå§‹åŒ–');
      cleanup();
    }
  
  }, [enabled, serviceUrl, isReady, isLoading, initializeService, cleanup]);
  
  return {
    processAudioData,
    flush,
    isReady,
    error,
  } as const;
}