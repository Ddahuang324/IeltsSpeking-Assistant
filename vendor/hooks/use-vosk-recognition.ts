import { useEffect, useRef, useState, useCallback } from 'react';

export interface UseVoskRecognitionOptions {
  enabled: boolean;
  modelUrl?: string;
  onResult?: (text: string) => void;
  onPartialResult?: (text: string) => void;
  onError?: (error: string) => void;
}

export function useVoskRecognition({
  enabled,
  modelUrl = '/models/vosk-model-small-en-us-0.15.tar.gz',
  onResult,
  onPartialResult,
  onError,
}: UseVoskRecognitionOptions) {
  console.log('ğŸ¤ useVoskRecognition åˆå§‹åŒ–:', { enabled, modelUrl });
  console.log('ğŸ¤ useVoskRecognition å‚æ•°è¯¦æƒ…:', { 
    enabled, 
    modelUrl, 
    hasOnResult: !!onResult, 
    hasOnPartialResult: !!onPartialResult, 
    hasOnError: !!onError 
  });
  
  // å¼ºåˆ¶è¾“å‡ºåˆ°window.consoleç¡®ä¿æ—¥å¿—å¯è§
  if (typeof window !== 'undefined') {
    window.console.log('ğŸ¤ [VOSK] useVoskRecognition åˆå§‹åŒ–:', { enabled, modelUrl });
  }
  const [isLoading, setIsLoading] = useState(false);
  const [isReady, setIsReady] = useState(false);
  const [error, setError] = useState<string | null>(null);
  
  const modelRef = useRef<any | null>(null);
  const recognizerRef = useRef<any | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  
  // åˆå§‹åŒ– Vosk æ¨¡å‹
  const initializeVosk = useCallback(async () => {
    if (!enabled || isReady || isLoading) return;
    
    try {
      console.log('ğŸ¤ å¼€å§‹åˆå§‹åŒ– Vosk æ¨¡å‹...', { enabled, modelUrl });
      setIsLoading(true);
      setError(null);
      
      // åŠ¨æ€å¯¼å…¥ vosk-browser
      console.log('ğŸ“¦ å¼€å§‹åŠ¨æ€å¯¼å…¥ vosk-browser...');
      let createModel;
      try {
        const voskModule = await import('vosk-browser');
        console.log('âœ… Vosk æ¨¡å—åŠ è½½æˆåŠŸ:', voskModule);
        console.log('ğŸ” æ¨¡å—å†…å®¹:', Object.keys(voskModule));
        createModel = voskModule.createModel;
        console.log('âœ… createModel å‡½æ•°:', typeof createModel);
        
        if (!createModel) {
          console.log('ğŸ” å°è¯•ä» default è·å– createModel');
          createModel = voskModule.default?.createModel;
          console.log('âœ… default.createModel å‡½æ•°:', typeof createModel);
        }
        
      } catch (importError: any) {
         console.error('âŒ å¯¼å…¥ vosk-browser å¤±è´¥:', importError);
         console.error('âŒ é”™è¯¯è¯¦æƒ…:', {
           message: importError?.message,
           stack: importError?.stack,
           name: importError?.name
         });
         throw new Error(`Failed to import vosk-browser: ${importError?.message || String(importError)}`);
       }
      
      if (!createModel) {
        throw new Error('createModel å‡½æ•°ä¸å­˜åœ¨');
      }
      
      // åˆ›å»ºæ¨¡å‹
      console.log('ğŸ“¥ å¼€å§‹åŠ è½½æ¨¡å‹æ–‡ä»¶:', modelUrl);
      const model = await createModel(modelUrl);
      console.log('ğŸ“¦ æ¨¡å‹å¯¹è±¡åˆ›å»ºæˆåŠŸ:', model);
      console.log('ğŸ” æ¨¡å‹å¯¹è±¡æ–¹æ³•:', model ? Object.keys(model) : 'model is null');
      modelRef.current = model;
      console.log('ğŸ”„ æ¨¡å‹åˆ›å»ºå®Œæˆï¼Œç­‰å¾…åŠ è½½...');
      
      // ç›‘å¬æ¨¡å‹åŠ è½½äº‹ä»¶
      model.on('load', (message: any) => {
        console.log('ğŸ“¦ æ¨¡å‹åŠ è½½äº‹ä»¶:', message);
        if (message.result) {
          console.log('âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼Œåˆ›å»ºè¯†åˆ«å™¨...');
          // åˆ›å»ºè¯†åˆ«å™¨ (éœ€è¦ä¼ å…¥ sampleRate)
          const recognizer = new model.KaldiRecognizer(16000);
          recognizerRef.current = recognizer;
          console.log('ğŸ¯ è¯†åˆ«å™¨åˆ›å»ºæˆåŠŸ');
          
          // è®¾ç½®è¯†åˆ«å™¨äº‹ä»¶ç›‘å¬
          recognizer.on('result', (message: any) => {
            console.log('ğŸ¤ Vosk è¯†åˆ«ç»“æœ:', message);
            if (message?.result?.text) {
              const text = message.result.text.trim();
              if (text && onResult) {
                console.log('ğŸ“ è°ƒç”¨ onResult:', text);
                onResult(text);
              }
            }
          });
          
          recognizer.on('partialresult', (message: any) => {
            console.log('ğŸ¤ Vosk éƒ¨åˆ†ç»“æœ:', message);
            if (message?.result?.partial) {
              const text = message.result.partial.trim();
              if (text && onPartialResult) {
                console.log('ğŸ“ è°ƒç”¨ onPartialResult:', text);
                onPartialResult(text);
              }
            }
          });
          
          setIsReady(true);
          setIsLoading(false);
          console.log('ğŸš€ Vosk åˆå§‹åŒ–å®Œæˆï¼Œå‡†å¤‡æ¥æ”¶éŸ³é¢‘æ•°æ®');
        } else {
          throw new Error('Failed to load Vosk model');
        }
      });
      
      model.on('error', (message: any) => {
        const errorMsg = `Vosk model error: ${message.error || 'Unknown error'}`;
        setError(errorMsg);
        setIsLoading(false);
        if (onError) {
          onError(errorMsg);
        }
      });
      
    } catch (err) {
      const errorMsg = `Failed to initialize Vosk: ${err instanceof Error ? err.message : String(err)}`;
      setError(errorMsg);
      setIsLoading(false);
      if (onError) {
        onError(errorMsg);
      }
    }
  }, [enabled, modelUrl, onResult, onPartialResult, onError, isReady, isLoading]);
  
  // å¤„ç†éŸ³é¢‘æ•°æ®
  const processAudioData = useCallback((audioData: ArrayBuffer, sampleRate: number = 16000) => {
    console.log('ğŸ¤ processAudioData è¢«è°ƒç”¨:', { 
      hasRecognizer: !!recognizerRef.current, 
      isReady, 
      bufferSize: audioData.byteLength 
    });
    
    if (!isReady || !recognizerRef.current) {
      console.log('âš ï¸ Vosk æœªå‡†å¤‡å¥½æˆ–è¯†åˆ«å™¨ä¸å­˜åœ¨:', { isReady, hasRecognizer: !!recognizerRef.current });
      return;
    }
    
    try {
      console.log('ğŸµ å¤„ç†éŸ³é¢‘æ•°æ®:', { dataLength: audioData.byteLength, sampleRate });
      
      // åˆ›å»º AudioContextï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
      if (!audioContextRef.current) {
        audioContextRef.current = new AudioContext({ sampleRate: 16000 }); // Voskæ¨¡å‹éœ€è¦16000Hz
        console.log('ğŸ”Š åˆ›å»º AudioContextï¼Œé‡‡æ ·ç‡: 16000Hz');
      }
      
      // å°† ArrayBuffer è½¬æ¢ä¸º Float32Arrayï¼ˆVosk éœ€è¦çš„æ ¼å¼ï¼‰
      const int16Array = new Int16Array(audioData);
      let float32Array = new Float32Array(int16Array.length);
      
      // å°† Int16 è½¬æ¢ä¸º Float32 (-1.0 åˆ° 1.0 èŒƒå›´)
      for (let i = 0; i < int16Array.length; i++) {
        float32Array[i] = int16Array[i] / 32768.0;
      }
      
      // å¦‚æœè¾“å…¥é‡‡æ ·ç‡ä¸æ˜¯16000Hzï¼Œéœ€è¦é‡é‡‡æ ·
      if (sampleRate !== 16000) {
        console.log(`ğŸ”„ é‡é‡‡æ ·: ${sampleRate}Hz -> 16000Hz`);
        const resampleRatio = 16000 / sampleRate;
        const resampledLength = Math.floor(float32Array.length * resampleRatio);
        const resampledArray = new Float32Array(resampledLength);
        
        // ç®€å•çš„çº¿æ€§æ’å€¼é‡é‡‡æ ·
        for (let i = 0; i < resampledLength; i++) {
          const sourceIndex = i / resampleRatio;
          const index = Math.floor(sourceIndex);
          const fraction = sourceIndex - index;
          
          if (index + 1 < float32Array.length) {
            resampledArray[i] = float32Array[index] * (1 - fraction) + float32Array[index + 1] * fraction;
          } else {
            resampledArray[i] = float32Array[index];
          }
        }
        
        float32Array = resampledArray;
        console.log('ğŸ”„ é‡é‡‡æ ·å®Œæˆ:', { 
          originalSamples: int16Array.length, 
          resampledSamples: float32Array.length,
          originalSampleRate: sampleRate,
          targetSampleRate: 16000
        });
      } else {
         console.log('ğŸ”„ éŸ³é¢‘æ•°æ®è½¬æ¢å®Œæˆ:', { 
           originalSamples: int16Array.length, 
           convertedSamples: float32Array.length,
           sampleRange: `${Math.min(...Array.from(float32Array))} to ${Math.max(...Array.from(float32Array))}`
         });
      }
      
      // å‘é€ Float32Array åˆ° Vosk è¯†åˆ«å™¨
      console.log('ğŸ“¤ å‘é€éŸ³é¢‘æ•°æ®åˆ° Vosk è¯†åˆ«å™¨ (Float32Array)');
      const result = recognizerRef.current.acceptWaveformFloat(float32Array, sampleRate);
      console.log('ğŸ¤ Vosk acceptWaveform è¿”å›:', result);
      
      if (result) {
        const resultObj = JSON.parse(recognizerRef.current.result());
        console.log('ğŸ¯ Vosk æœ€ç»ˆç»“æœå¯¹è±¡:', resultObj);
        if (resultObj.text) {
          console.log('ğŸ¯ Vosk è¯†åˆ«ç»“æœ:', resultObj.text);
          onResult?.(resultObj.text);
        }
      } else {
        const partialObj = JSON.parse(recognizerRef.current.partialResult());
        console.log('ğŸ¤ Vosk éƒ¨åˆ†ç»“æœå¯¹è±¡:', partialObj);
        if (partialObj.partial) {
          console.log('ğŸ¤ Vosk éƒ¨åˆ†ç»“æœ:', partialObj.partial);
          onPartialResult?.(partialObj.partial);
        }
      }
      
    } catch (err) {
      const errorMsg = `Audio processing error: ${err instanceof Error ? err.message : String(err)}`;
      console.error('âŒ Vosk å¤„ç†éŸ³é¢‘æ•°æ®é”™è¯¯:', err);
      setError(errorMsg);
      if (onError) {
        onError(errorMsg);
      }
    }
  }, [isReady, onError, onResult, onPartialResult]);
  
  // æ¸…ç†èµ„æº
  const cleanup = useCallback(() => {
    if (recognizerRef.current) {
      try {
        recognizerRef.current.remove();
      } catch (e) {
        // å¿½ç•¥æ¸…ç†é”™è¯¯
      }
      recognizerRef.current = null;
    }
    
    if (modelRef.current) {
      try {
        modelRef.current.terminate();
      } catch (e) {
        // å¿½ç•¥æ¸…ç†é”™è¯¯
      }
      modelRef.current = null;
    }
    
    if (audioContextRef.current) {
      try {
        audioContextRef.current.close();
      } catch (e) {
        // å¿½ç•¥æ¸…ç†é”™è¯¯
      }
      audioContextRef.current = null;
    }
    
    setIsReady(false);
    setError(null);
  }, []);
  
  // åˆå§‹åŒ–æ•ˆæœ
  useEffect(() => {
    console.log('ğŸ¤ useVoskRecognition useEffect è§¦å‘:', { enabled, modelUrl });
    if (enabled) {
      console.log('ğŸ¤ å¼€å§‹åˆå§‹åŒ– Vosk');
      initializeVosk();
    } else {
      console.log('ğŸ¤ Vosk å·²ç¦ç”¨ï¼Œè·³è¿‡åˆå§‹åŒ–');
      cleanup();
    }
    
    return () => {
      console.log('ğŸ¤ æ¸…ç† Vosk èµ„æº');
      cleanup();
    };
  }, [enabled, initializeVosk, cleanup]);
  
  return {
    isLoading,
    isReady,
    error,
    processAudioData,
    cleanup,
  };
}